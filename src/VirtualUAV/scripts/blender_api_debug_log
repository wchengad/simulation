1. Memory debugging
1.1 
If blender's occupied memory keep increasing, open the memory debug option in terminal by adding "----debug-memory". bpy.ops.wm.memory_statistics() with print the detailed memory usage of all kinds of items.
check [https://docs.blender.org/manual/de/dev/advanced/command_line/arguments.html] for more details
1.2
use "$ watch -n 5 free -m" command to monitor computer memory usage of memory or cache.
1.3 
In blender API, user_clear or user_remove will clean memory without any remain, but remove() will;
reset_joint_positions() in main.py or main_part1.py has a item to load a mesh and use remove() to delete the mesh, but it will still exits in blender's memory leading increasing memory in memory_statistics.
1.4
Blender will cache the texture of rendered image by default to speed up rendering for next image, so be aware of enabling use_free_image_textures in render settings.(Although it seems to be have no effect on memory usage reduction)

2. GPU rendering
2.1 
First, you should enable GPU in User Preference -> System -> Computer Device, select CUDA and corresponding graphics card, otherwise blender will use CPU to render image which through my test, is hard to reduce memory usage accumulating. 
check [https://docs.blender.org/manual/en/dev/render/cycles/gpu_rendering.html] for more detail.
2.2
Also, you should use cycle render instead of blender render if you want to enable GPU rendering. 
bpy.context.scene.render.engine = 'CYCLES' # select render engine
bpy.context.scene.cycles.device = 'GPU' # select render device
On the other hand, all other render settings are not contained in CycleRenderSetting type, you can preserve all the settings modified in RenderSetting type.
2.3
To run in multi-threads, you can use following statements.
bpy.context.scene.render.threads_mode = 'FIXED' # default value is 'AUTO'
bpy.context.scene.render.threads = 6 # set threads you want to use

3. Blender visualization debugging
3.1
For all the coordinate system problems, it's hard to figure out the exact rotation or translation of the armature or camera, or the relationship between their local and global coordinates. One can start the blender in terminator by "$ cd $BLENDER_PATH & $ ./blender", and run your script in the script interface, or test or obtain the value of some objects in the concole interface. The reason by using terminal is that all the error information will print in the terminal where blender started.

4. Blender camera model(Desire to modify blender camera intrinsic parameter accrods to kinect's)
Blender's default camera model is 16:9 in sensor size. So however you modify the horizontal or vertical FOV angle when your render resolution is 4:3, it will not output the desired FOV with always fit it into 16:9. My comprehension is that, render resolution has no relation to camera horizontal/vertical ratio. Because Kinect has a 58.5 HFOV and 45.6 VFOV, but with 4:3 resolution. So kinect has a (58.5/4):(45.6/3) pixel aspect ratio, in [https://social.msdn.microsoft.com/Forums/en-US/b517307c-08d7-4435-a968-1d63a4e42028/camera-intrinsic-parameters?forum=kinectsdk] there exits a mistake on pixel aspect ratio. So, we should firstly modify pixel aspect ratio in render. Then, modify the greater FOV in HFOV or VFOV in Camera.
To check the result. You can check the (bpy.data.objects['Camera'].data.angle_y * 240 / 180) and see if it equals to math.radians(45.6). So from now, I guess that, blender renderer will align the render image to bigger FOV axis, and borden or shrimk another axis when the resolution doesn't meet. In my case, the y axis has been extented to have more pixels included other than 16:9.
